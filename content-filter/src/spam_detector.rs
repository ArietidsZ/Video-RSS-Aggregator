use anyhow::{Context, Result};
use bloomfilter::Bloom;
use dashmap::DashMap;
use levenshtein::levenshtein;
use minhash_rs::MinHash;
use serde::{Deserialize, Serialize};
use simhash::simhash;
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tracing::{debug, error, info, warn};
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SpamDetectionResult {
    pub content_id: String,
    pub is_spam: bool,
    pub spam_score: f32,
    pub spam_indicators: Vec<SpamIndicator>,
    pub duplicate_of: Option<String>,
    pub similarity_score: Option<f32>,
    pub detection_method: DetectionMethod,
    pub confidence: f32,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SpamIndicator {
    pub indicator_type: SpamIndicatorType,
    pub weight: f32,
    pub details: String,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum SpamIndicatorType {
    ExcessiveCapitalization,
    RepeatedCharacters,
    SpamKeywords,
    SuspiciousLinks,
    ExcessiveEmojis,
    PhoneNumbers,
    EmailHarvesting,
    MonetaryOffers,
    ClickBait,
    LowContentQuality,
    HighLinkDensity,
    MaliciousPatterns,
    RepeatedContent,
    AutoGeneratedText,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum DetectionMethod {
    RuleBased,
    MachineLearning,
    Heuristic,
    Hybrid,
}

#[derive(Debug, Clone)]
pub struct SpamDetector {
    // Duplicate detection
    simhash_index: Arc<RwLock<HashMap<u64, Vec<ContentFingerprint>>>>,
    minhash_index: Arc<RwLock<Vec<MinHashSignature>>>,
    bloom_filter: Arc<RwLock<Bloom<String>>>,

    // Spam detection
    spam_patterns: Arc<Vec<SpamPattern>>,
    keyword_blacklist: Arc<HashSet<String>>,
    url_blacklist: Arc<HashSet<String>>,

    // Caching
    cache: Arc<DashMap<String, SpamDetectionResult>>,

    // Configuration
    config: SpamDetectorConfig,
    statistics: Arc<RwLock<SpamStatistics>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SpamDetectorConfig {
    pub duplicate_threshold: f32,
    pub spam_threshold: f32,
    pub simhash_distance_threshold: u32,
    pub minhash_similarity_threshold: f32,
    pub cache_ttl: Duration,
    pub max_content_length: usize,
    pub enable_ml_detection: bool,
    pub strict_mode: bool,
}

impl Default for SpamDetectorConfig {
    fn default() -> Self {
        Self {
            duplicate_threshold: 0.85,
            spam_threshold: 0.7,
            simhash_distance_threshold: 3,
            minhash_similarity_threshold: 0.8,
            cache_ttl: Duration::from_secs(3600),
            max_content_length: 50000,
            enable_ml_detection: true,
            strict_mode: false,
        }
    }
}

#[derive(Debug, Clone)]
struct ContentFingerprint {
    content_id: String,
    simhash: u64,
    minhash: Vec<u64>,
    timestamp: Instant,
    content_length: usize,
}

#[derive(Debug, Clone)]
struct MinHashSignature {
    content_id: String,
    signature: Vec<u64>,
}

#[derive(Debug, Clone)]
struct SpamPattern {
    pattern: regex::Regex,
    weight: f32,
    indicator_type: SpamIndicatorType,
    description: String,
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct SpamStatistics {
    pub total_checked: u64,
    pub spam_detected: u64,
    pub duplicates_found: u64,
    pub false_positives: u64,
    pub false_negatives: u64,
    pub average_processing_time_ms: f64,
    pub indicator_counts: HashMap<String, u64>,
}

impl SpamDetector {
    pub async fn new(config: SpamDetectorConfig) -> Result<Self> {
        let bloom_filter = Bloom::new_for_fp_rate(1000000, 0.01);

        Ok(Self {
            simhash_index: Arc::new(RwLock::new(HashMap::new())),
            minhash_index: Arc::new(RwLock::new(Vec::new())),
            bloom_filter: Arc::new(RwLock::new(bloom_filter)),
            spam_patterns: Arc::new(Self::load_spam_patterns()),
            keyword_blacklist: Arc::new(Self::load_keyword_blacklist()),
            url_blacklist: Arc::new(Self::load_url_blacklist()),
            cache: Arc::new(DashMap::new()),
            config,
            statistics: Arc::new(RwLock::new(SpamStatistics::default())),
        })
    }

    pub async fn check_content(&self, content_id: &str, content: &str) -> Result<SpamDetectionResult> {
        // Check cache
        if let Some(cached) = self.cache.get(content_id) {
            if cached.timestamp.timestamp() + self.config.cache_ttl.as_secs() as i64
                > chrono::Utc::now().timestamp() {
                return Ok(cached.clone());
            }
        }

        let start = Instant::now();

        // Normalize content
        let normalized = self.normalize_content(content);

        // Check for duplicates
        let duplicate_result = self.check_duplicates(content_id, &normalized).await?;

        // Check for spam
        let spam_indicators = self.detect_spam_indicators(&normalized).await?;

        // Calculate spam score
        let spam_score = self.calculate_spam_score(&spam_indicators);

        // Determine if content is spam
        let is_spam = spam_score >= self.config.spam_threshold || duplicate_result.is_some();

        // Store fingerprint for future duplicate detection
        if !is_spam {
            self.store_fingerprint(content_id, &normalized).await?;
        }

        let result = SpamDetectionResult {
            content_id: content_id.to_string(),
            is_spam,
            spam_score,
            spam_indicators,
            duplicate_of: duplicate_result.as_ref().map(|d| d.0.clone()),
            similarity_score: duplicate_result.map(|d| d.1),
            detection_method: if self.config.enable_ml_detection {
                DetectionMethod::Hybrid
            } else {
                DetectionMethod::RuleBased
            },
            confidence: if is_spam { spam_score.min(0.99) } else { 1.0 - spam_score },
            timestamp: chrono::Utc::now(),
        };

        // Update statistics
        self.update_statistics(&result, start.elapsed()).await;

        // Cache result
        self.cache.insert(content_id.to_string(), result.clone());

        Ok(result)
    }

    async fn check_duplicates(&self, content_id: &str, content: &str) -> Result<Option<(String, f32)>> {
        // Quick bloom filter check
        {
            let bloom = self.bloom_filter.read().await;
            if !bloom.check(&content_id.to_string()) {
                // Content ID not seen before, likely not a duplicate
                return Ok(None);
            }
        }

        // Calculate simhash
        let content_simhash = simhash(content);

        // Check simhash index
        {
            let index = self.simhash_index.read().await;
            let bucket = content_simhash >> 56;  // Use first 8 bits as bucket

            if let Some(fingerprints) = index.get(&bucket) {
                for fp in fingerprints {
                    let distance = Self::hamming_distance(content_simhash, fp.simhash);
                    if distance <= self.config.simhash_distance_threshold {
                        // Potential duplicate found, verify with MinHash
                        let similarity = self.calculate_minhash_similarity(content, &fp.content_id).await?;
                        if similarity >= self.config.duplicate_threshold {
                            return Ok(Some((fp.content_id.clone(), similarity)));
                        }
                    }
                }
            }
        }

        // Check exact duplicates with MinHash
        let minhash = self.calculate_minhash(content)?;
        {
            let index = self.minhash_index.read().await;
            for sig in index.iter() {
                let similarity = Self::jaccard_similarity(&minhash, &sig.signature);
                if similarity >= self.config.duplicate_threshold {
                    return Ok(Some((sig.content_id.clone(), similarity)));
                }
            }
        }

        Ok(None)
    }

    async fn detect_spam_indicators(&self, content: &str) -> Result<Vec<SpamIndicator>> {
        let mut indicators = Vec::new();

        // Check excessive capitalization
        let caps_ratio = self.calculate_caps_ratio(content);
        if caps_ratio > 0.5 {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::ExcessiveCapitalization,
                weight: caps_ratio,
                details: format!("{:.0}% capital letters", caps_ratio * 100.0),
            });
        }

        // Check repeated characters
        if let Some(repeated) = self.find_repeated_characters(content) {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::RepeatedCharacters,
                weight: 0.8,
                details: format!("Found repeated pattern: {}", repeated),
            });
        }

        // Check spam keywords
        let keyword_count = self.count_spam_keywords(content);
        if keyword_count > 0 {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::SpamKeywords,
                weight: (keyword_count as f32 / 10.0).min(1.0),
                details: format!("Found {} spam keywords", keyword_count),
            });
        }

        // Check suspicious links
        let link_density = self.calculate_link_density(content);
        if link_density > 0.2 {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::HighLinkDensity,
                weight: link_density,
                details: format!("Link density: {:.0}%", link_density * 100.0),
            });
        }

        // Check for suspicious URLs
        if self.contains_suspicious_urls(content) {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::SuspiciousLinks,
                weight: 0.9,
                details: "Contains blacklisted or suspicious URLs".to_string(),
            });
        }

        // Check excessive emojis
        let emoji_ratio = self.calculate_emoji_ratio(content);
        if emoji_ratio > 0.1 {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::ExcessiveEmojis,
                weight: emoji_ratio * 2.0,
                details: format!("{:.0}% emoji content", emoji_ratio * 100.0),
            });
        }

        // Check for phone numbers
        if self.contains_phone_numbers(content) {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::PhoneNumbers,
                weight: 0.6,
                details: "Contains phone numbers".to_string(),
            });
        }

        // Check for monetary offers
        if self.contains_monetary_offers(content) {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::MonetaryOffers,
                weight: 0.8,
                details: "Contains monetary offers or prices".to_string(),
            });
        }

        // Check clickbait patterns
        if self.is_clickbait(content) {
            indicators.push(SpamIndicator {
                indicator_type: SpamIndicatorType::ClickBait,
                weight: 0.7,
                details: "Clickbait patterns detected".to_string(),
            });
        }

        // Apply spam patterns
        for pattern in self.spam_patterns.iter() {
            if pattern.pattern.is_match(content) {
                indicators.push(SpamIndicator {
                    indicator_type: pattern.indicator_type.clone(),
                    weight: pattern.weight,
                    details: pattern.description.clone(),
                });
            }
        }

        Ok(indicators)
    }

    fn calculate_spam_score(&self, indicators: &[SpamIndicator]) -> f32 {
        if indicators.is_empty() {
            return 0.0;
        }

        let total_weight: f32 = indicators.iter().map(|i| i.weight).sum();
        let max_weight = indicators.iter().map(|i| i.weight).fold(0.0f32, f32::max);

        // Weighted average with boost for multiple indicators
        let base_score = total_weight / indicators.len() as f32;
        let boost = (indicators.len() as f32 / 10.0).min(0.3);

        (base_score + boost).max(max_weight).min(1.0)
    }

    async fn store_fingerprint(&self, content_id: &str, content: &str) -> Result<()> {
        let simhash_value = simhash(content);
        let minhash = self.calculate_minhash(content)?;

        // Store in bloom filter
        {
            let mut bloom = self.bloom_filter.write().await;
            bloom.set(&content_id.to_string());
        }

        // Store simhash
        {
            let mut index = self.simhash_index.write().await;
            let bucket = simhash_value >> 56;

            let fingerprint = ContentFingerprint {
                content_id: content_id.to_string(),
                simhash: simhash_value,
                minhash: minhash.clone(),
                timestamp: Instant::now(),
                content_length: content.len(),
            };

            index.entry(bucket).or_insert_with(Vec::new).push(fingerprint);
        }

        // Store MinHash signature
        {
            let mut index = self.minhash_index.write().await;
            index.push(MinHashSignature {
                content_id: content_id.to_string(),
                signature: minhash,
            });

            // Limit index size
            if index.len() > 10000 {
                index.drain(0..1000);
            }
        }

        Ok(())
    }

    fn normalize_content(&self, content: &str) -> String {
        // Remove extra whitespace, convert to lowercase for comparison
        content
            .chars()
            .filter(|c| !c.is_whitespace() || *c == ' ')
            .collect::<String>()
            .split_whitespace()
            .collect::<Vec<_>>()
            .join(" ")
            .to_lowercase()
    }

    fn calculate_caps_ratio(&self, content: &str) -> f32 {
        let letters: Vec<char> = content.chars().filter(|c| c.is_alphabetic()).collect();
        if letters.is_empty() {
            return 0.0;
        }

        let caps_count = letters.iter().filter(|c| c.is_uppercase()).count();
        caps_count as f32 / letters.len() as f32
    }

    fn find_repeated_characters(&self, content: &str) -> Option<String> {
        let re = regex::Regex::new(r"(.)\1{4,}").ok()?;
        re.find(content).map(|m| m.as_str().to_string())
    }

    fn count_spam_keywords(&self, content: &str) -> usize {
        let lower = content.to_lowercase();
        self.keyword_blacklist.iter()
            .filter(|keyword| lower.contains(keyword.as_str()))
            .count()
    }

    fn calculate_link_density(&self, content: &str) -> f32 {
        let url_re = regex::Regex::new(r"https?://[^\s]+").unwrap();
        let urls: Vec<_> = url_re.find_iter(content).collect();

        if content.is_empty() {
            return 0.0;
        }

        let url_length: usize = urls.iter().map(|m| m.as_str().len()).sum();
        url_length as f32 / content.len() as f32
    }

    fn contains_suspicious_urls(&self, content: &str) -> bool {
        let url_re = regex::Regex::new(r"https?://([^/\s]+)").unwrap();

        for cap in url_re.captures_iter(content) {
            if let Some(domain) = cap.get(1) {
                let domain_str = domain.as_str().to_lowercase();
                if self.url_blacklist.contains(&domain_str) {
                    return true;
                }
                // Check for URL shorteners
                if domain_str.contains("bit.ly") || domain_str.contains("tinyurl")
                    || domain_str.contains("goo.gl") || domain_str.contains("t.co") {
                    return true;
                }
            }
        }

        false
    }

    fn calculate_emoji_ratio(&self, content: &str) -> f32 {
        let emoji_re = regex::Regex::new(r"[\p{Emoji}]").unwrap();
        let emoji_count = emoji_re.find_iter(content).count();

        if content.is_empty() {
            return 0.0;
        }

        emoji_count as f32 / content.chars().count() as f32
    }

    fn contains_phone_numbers(&self, content: &str) -> bool {
        let phone_re = regex::Regex::new(
            r"(?:\+?[1-9]\d{0,2}[\s.-]?)?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}"
        ).unwrap();

        phone_re.is_match(content)
    }

    fn contains_monetary_offers(&self, content: &str) -> bool {
        let money_re = regex::Regex::new(
            r"(?i)(\$\d+|free money|earn \$|make money|get paid|cash prize|winner selected)"
        ).unwrap();

        money_re.is_match(content)
    }

    fn is_clickbait(&self, content: &str) -> bool {
        let clickbait_patterns = [
            "you won't believe",
            "shocking",
            "this one trick",
            "doctors hate",
            "click here",
            "limited time",
            "act now",
            "don't miss out",
        ];

        let lower = content.to_lowercase();
        clickbait_patterns.iter().any(|pattern| lower.contains(pattern))
    }

    fn calculate_minhash(&self, content: &str) -> Result<Vec<u64>> {
        let shingles = self.generate_shingles(content, 3);
        let num_hashes = 128;
        let mut minhash = vec![u64::MAX; num_hashes];

        for shingle in shingles {
            let hash = blake3::hash(shingle.as_bytes());
            let hash_bytes = hash.as_bytes();

            for i in 0..num_hashes {
                let hash_value = u64::from_le_bytes([
                    hash_bytes[i % 32],
                    hash_bytes[(i + 1) % 32],
                    hash_bytes[(i + 2) % 32],
                    hash_bytes[(i + 3) % 32],
                    hash_bytes[(i + 4) % 32],
                    hash_bytes[(i + 5) % 32],
                    hash_bytes[(i + 6) % 32],
                    hash_bytes[(i + 7) % 32],
                ]);

                if hash_value < minhash[i] {
                    minhash[i] = hash_value;
                }
            }
        }

        Ok(minhash)
    }

    async fn calculate_minhash_similarity(&self, content: &str, other_id: &str) -> Result<f32> {
        let minhash1 = self.calculate_minhash(content)?;

        let index = self.minhash_index.read().await;
        for sig in index.iter() {
            if sig.content_id == other_id {
                return Ok(Self::jaccard_similarity(&minhash1, &sig.signature));
            }
        }

        Ok(0.0)
    }

    fn generate_shingles(&self, text: &str, k: usize) -> Vec<String> {
        let chars: Vec<char> = text.chars().collect();
        let mut shingles = Vec::new();

        for i in 0..chars.len().saturating_sub(k - 1) {
            let shingle: String = chars[i..i + k].iter().collect();
            shingles.push(shingle);
        }

        shingles
    }

    fn hamming_distance(a: u64, b: u64) -> u32 {
        (a ^ b).count_ones()
    }

    fn jaccard_similarity(set1: &[u64], set2: &[u64]) -> f32 {
        if set1.len() != set2.len() {
            return 0.0;
        }

        let matching = set1.iter()
            .zip(set2.iter())
            .filter(|(a, b)| a == b)
            .count();

        matching as f32 / set1.len() as f32
    }

    async fn update_statistics(&self, result: &SpamDetectionResult, duration: Duration) {
        let mut stats = self.statistics.write().await;

        stats.total_checked += 1;

        if result.is_spam {
            stats.spam_detected += 1;
        }

        if result.duplicate_of.is_some() {
            stats.duplicates_found += 1;
        }

        for indicator in &result.spam_indicators {
            let key = format!("{:?}", indicator.indicator_type);
            *stats.indicator_counts.entry(key).or_insert(0) += 1;
        }

        // Update average processing time
        let current_avg = stats.average_processing_time_ms;
        let current_count = stats.total_checked as f64;
        stats.average_processing_time_ms =
            (current_avg * (current_count - 1.0) + duration.as_millis() as f64) / current_count;
    }

    fn load_spam_patterns() -> Vec<SpamPattern> {
        vec![
            SpamPattern {
                pattern: regex::Regex::new(r"(?i)(viagra|cialis|levitra|pharmacy)").unwrap(),
                weight: 0.9,
                indicator_type: SpamIndicatorType::SpamKeywords,
                description: "Pharmaceutical spam keywords".to_string(),
            },
            SpamPattern {
                pattern: regex::Regex::new(r"(?i)(casino|poker|gambling|bet now)").unwrap(),
                weight: 0.8,
                indicator_type: SpamIndicatorType::SpamKeywords,
                description: "Gambling spam keywords".to_string(),
            },
            SpamPattern {
                pattern: regex::Regex::new(r"(?i)(weight loss|lose \d+ pounds|diet pill)").unwrap(),
                weight: 0.7,
                indicator_type: SpamIndicatorType::SpamKeywords,
                description: "Diet/weight loss spam".to_string(),
            },
            SpamPattern {
                pattern: regex::Regex::new(r"[A-Z\s]{10,}").unwrap(),
                weight: 0.6,
                indicator_type: SpamIndicatorType::ExcessiveCapitalization,
                description: "Excessive caps lock usage".to_string(),
            },
        ]
    }

    fn load_keyword_blacklist() -> HashSet<String> {
        let keywords = vec![
            "viagra", "cialis", "pharmacy", "casino", "poker",
            "weight loss", "free money", "click here", "act now",
            "limited time", "winner", "congratulations", "prize",
            "cheap", "discount", "offer expires", "order now",
        ];

        keywords.into_iter().map(|s| s.to_string()).collect()
    }

    fn load_url_blacklist() -> HashSet<String> {
        // In production, load from database or external file
        HashSet::new()
    }

    pub async fn report_false_positive(&self, content_id: &str) {
        let mut stats = self.statistics.write().await;
        stats.false_positives += 1;

        // Remove from cache
        self.cache.remove(content_id);

        info!("False positive reported for content: {}", content_id);
    }

    pub async fn report_false_negative(&self, content_id: &str) {
        let mut stats = self.statistics.write().await;
        stats.false_negatives += 1;

        // Remove from cache to force re-evaluation
        self.cache.remove(content_id);

        warn!("False negative reported for content: {}", content_id);
    }

    pub async fn get_statistics(&self) -> SpamStatistics {
        self.statistics.read().await.clone()
    }

    pub async fn clear_old_fingerprints(&self, max_age: Duration) {
        let now = Instant::now();
        let mut index = self.simhash_index.write().await;

        for fingerprints in index.values_mut() {
            fingerprints.retain(|fp| now.duration_since(fp.timestamp) < max_age);
        }

        // Remove empty buckets
        index.retain(|_, v| !v.is_empty());
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_spam_detection() {
        let config = SpamDetectorConfig::default();
        let detector = SpamDetector::new(config).await.unwrap();

        let spam_content = "FREE MONEY!!! CLICK HERE NOW!!!";
        let result = detector.check_content("test1", spam_content).await.unwrap();

        assert!(result.is_spam);
        assert!(result.spam_score > 0.5);
    }

    #[tokio::test]
    async fn test_duplicate_detection() {
        let config = SpamDetectorConfig::default();
        let detector = SpamDetector::new(config).await.unwrap();

        let content = "This is a test content for duplicate detection.";

        // First check should not find duplicates
        let result1 = detector.check_content("test1", content).await.unwrap();
        assert!(result1.duplicate_of.is_none());

        // Second check with similar content should find duplicate
        let similar_content = "This is a test content for duplicate detection!";
        let result2 = detector.check_content("test2", similar_content).await.unwrap();

        // May or may not find duplicate based on threshold
    }
}