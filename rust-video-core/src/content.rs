use crate::{
    types::*,
    utils::{clean_html, extract_video_id},
    Result,
};
use regex::Regex;
use reqwest::Client;
use scraper::{Html, Selector};
use serde_json::Value;
use std::collections::HashMap;
use tracing::{debug, info, warn};

pub struct ContentAnalyzer {
    client: Client,
}

impl ContentAnalyzer {
    pub fn new() -> Result<Self> {
        let client = Client::builder()
            .user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
            .timeout(std::time::Duration::from_secs(30))
            .build()?;

        Ok(Self { client })
    }

    pub async fn analyze_video(&self, video: &VideoInfo) -> Result<ContentSummary> {
        info!("Analyzing video content: {}", video.title);

        let keywords = self.extract_keywords(&video.title, &video.description, &video.tags);
        let content_type = self.classify_content(video);
        let sentiment = self.analyze_sentiment(&video.title, &video.description);

        let ai_summary = self.generate_content_summary(video).await?;

        Ok(ContentSummary {
            ai_summary,
            keywords,
            sentiment,
            content_type,
        })
    }

    pub async fn batch_analyze(&self, videos: &[VideoInfo]) -> Result<Vec<AnalysisResult>> {
        info!("Batch analyzing {} videos", videos.len());

        let mut results = Vec::new();

        for video in videos {
            let start_time = std::time::Instant::now();

            match self.analyze_video(video).await {
                Ok(summary) => {
                    let processing_time = start_time.elapsed().as_millis() as u64;

                    results.push(AnalysisResult {
                        video: video.clone(),
                        summary,
                        processing_time_ms: processing_time,
                    });
                }
                Err(e) => {
                    warn!("Failed to analyze video {}: {}", video.id, e);
                    // Continue with other videos
                }
            }

            // Rate limiting
            tokio::time::sleep(std::time::Duration::from_millis(100)).await;
        }

        info!("Completed batch analysis: {} results", results.len());
        Ok(results)
    }

    async fn generate_content_summary(&self, video: &VideoInfo) -> Result<String> {
        // Try to get actual video content
        if let Ok(content_data) = self.fetch_video_page_content(&video.url).await {
            return Ok(self.analyze_page_content(&content_data, video));
        }

        // Fallback to metadata-based summary
        Ok(self.generate_metadata_summary(video))
    }

    async fn fetch_video_page_content(&self, url: &str) -> Result<String> {
        debug!("Fetching video page content from: {}", url);

        let response = self.client.get(url).send().await?;

        if !response.status().is_success() {
            return Err(crate::error::VideoRssError::Http(reqwest::Error::from(
                reqwest::ErrorKind::Request,
            )));
        }

        let content = response.text().await?;
        Ok(content)
    }

    fn analyze_page_content(&self, html: &str, video: &VideoInfo) -> String {
        let document = Html::parse_document(html);
        let mut summary_parts = Vec::new();

        // Try to extract meaningful content from the page
        if let Ok(selector) = Selector::parse("meta[name='description']") {
            if let Some(element) = document.select(&selector).next() {
                if let Some(content) = element.value().attr("content") {
                    if !content.is_empty() && content.len() > 10 {
                        summary_parts.push(format!("ğŸ“Œ æ ¸å¿ƒå†…å®¹ï¼š{}", content));
                    }
                }
            }
        }

        // Extract JSON-LD data if available
        if let Ok(selector) = Selector::parse("script[type='application/ld+json']") {
            for element in document.select(&selector) {
                if let Some(json_text) = element.text().next() {
                    if let Ok(json_data) = serde_json::from_str::<Value>(json_text) {
                        if let Some(description) = json_data["description"].as_str() {
                            summary_parts.push(format!("ğŸ’¬ è¯¦ç»†æè¿°ï¼š{}", description));
                            break;
                        }
                    }
                }
            }
        }

        // Add engagement metrics
        if video.view_count > 0 {
            summary_parts.push(format!(
                "[STATS] æ’­æ”¾{:,}æ¬¡ï¼Œäº’åŠ¨è‰¯å¥½",
                video.view_count
            ));
        }

        // Add hashtags/topics
        if !video.tags.is_empty() {
            let topics = video.tags
                .iter()
                .take(3)
                .cloned()
                .collect::<Vec<_>>()
                .join(", ");
            summary_parts.push(format!("ğŸ·ï¸ ä¸»è¦è¯é¢˜ï¼š{}", topics));
        }

        if summary_parts.is_empty() {
            self.generate_metadata_summary(video)
        } else {
            summary_parts.join(" | ")
        }
    }

    fn generate_metadata_summary(&self, video: &VideoInfo) -> String {
        let mut summary_parts = Vec::new();

        // Content type classification
        let title_lower = video.title.to_lowercase();
        if title_lower.contains("åˆé›†") || title_lower.contains("é›†åˆ") || title_lower.contains("ç²¾é€‰") {
            summary_parts.push(format!("ğŸ“¦ å†…å®¹åˆé›†ï¼š{}", video.title));
        } else if title_lower.contains("æ•™ç¨‹") || title_lower.contains("æ”»ç•¥") || title_lower.contains("æ–¹æ³•") {
            summary_parts.push(format!("ğŸ“š å®ç”¨æ•™ç¨‹ï¼š{}", video.title));
        } else if title_lower.contains("éŸ³ä¹") || title_lower.contains("æ­Œæ›²") || title_lower.contains("æ­Œå•") {
            summary_parts.push(format!("ğŸµ éŸ³ä¹å†…å®¹ï¼š{}", video.title));
        } else if title_lower.contains("æ¸¸æˆ") || title_lower.contains("å®å†µ") || title_lower.contains("è§£è¯´") {
            summary_parts.push(format!("ğŸ® æ¸¸æˆå†…å®¹ï¼š{}", video.title));
        } else {
            summary_parts.push(format!("ğŸ“¹ è§†é¢‘å†…å®¹ï¼š{}", video.title));
        }

        // Duration and engagement
        if let Some(duration) = video.duration {
            let minutes = duration / 60;
            summary_parts.push(format!("â±ï¸ æ—¶é•¿{}åˆ†é’Ÿï¼Œå·²æœ‰{:,}äººè§‚çœ‹", minutes, video.view_count));
        } else if video.view_count > 0 {
            summary_parts.push(format!("[STATS] å·²æœ‰{:,}äººè§‚çœ‹", video.view_count));
        }

        // Description summary
        if !video.description.is_empty() && video.description != "-" && video.description.len() > 10 {
            let desc_summary = if video.description.len() > 80 {
                format!("{}...", &video.description[..80])
            } else {
                video.description.clone()
            };
            summary_parts.push(format!("ğŸ“ ç®€ä»‹ï¼š{}", desc_summary));
        }

        // Tags
        if !video.tags.is_empty() {
            let main_tags = video.tags
                .iter()
                .take(3)
                .cloned()
                .collect::<Vec<_>>()
                .join(", ");
            summary_parts.push(format!("ğŸ·ï¸ ç›¸å…³è¯é¢˜ï¼š{}", main_tags));
        }

        // Creator info
        if !video.author.is_empty() {
            summary_parts.push(format!("ğŸ‘¤ åˆ›ä½œè€…ï¼š{}", video.author));
        }

        summary_parts.join(" | ")
    }

    fn extract_keywords(&self, title: &str, description: &str, tags: &[String]) -> Vec<String> {
        let mut keywords = Vec::new();

        // Extract from tags first (highest relevance)
        keywords.extend(tags.iter().take(5).cloned());

        // Extract from title
        keywords.extend(self.extract_keywords_from_text(title, 3));

        // Extract from description
        if !description.is_empty() {
            keywords.extend(self.extract_keywords_from_text(description, 5));
        }

        // Remove duplicates and limit
        keywords.sort();
        keywords.dedup();
        keywords.truncate(10);

        keywords
    }

    fn extract_keywords_from_text(&self, text: &str, limit: usize) -> Vec<String> {
        // Simple keyword extraction based on Chinese text patterns
        let chinese_word_pattern = Regex::new(r"[\u4e00-\u9fff]{2,}").unwrap();
        let mut keywords: Vec<String> = chinese_word_pattern
            .find_iter(text)
            .map(|m| m.as_str().to_string())
            .filter(|word| word.len() >= 2 && word.len() <= 6) // Reasonable word length
            .collect();

        // Remove common stop words
        let stop_words = ["è¿™ä¸ª", "é‚£ä¸ª", "å¯ä»¥", "æˆ‘ä»¬", "ä»–ä»¬", "ä»€ä¹ˆ", "æ€ä¹ˆ", "éå¸¸", "çœŸçš„", "è¿˜æ˜¯"];
        keywords.retain(|word| !stop_words.contains(&word.as_str()));

        keywords.truncate(limit);
        keywords
    }

    fn classify_content(&self, video: &VideoInfo) -> ContentType {
        let title_lower = video.title.to_lowercase();
        let desc_lower = video.description.to_lowercase();

        // Check tags first for more accurate classification
        for tag in &video.tags {
            let tag_lower = tag.to_lowercase();
            match tag_lower.as_str() {
                t if t.contains("æ•™ç¨‹") || t.contains("å­¦ä¹ ") || t.contains("æ•™è‚²") => {
                    return ContentType::Educational;
                }
                t if t.contains("æ¸¸æˆ") || t.contains("ç”µç«") => {
                    return ContentType::Gaming;
                }
                t if t.contains("éŸ³ä¹") || t.contains("æ­Œæ›²") => {
                    return ContentType::Music;
                }
                t if t.contains("ç§‘æŠ€") || t.contains("æŠ€æœ¯") => {
                    return ContentType::Technology;
                }
                t if t.contains("æ–°é—»") || t.contains("æ—¶äº‹") => {
                    return ContentType::News;
                }
                _ => {}
            }
        }

        // Fallback to title and description analysis
        let combined_text = format!("{} {}", title_lower, desc_lower);

        if combined_text.contains("æ•™ç¨‹") || combined_text.contains("å­¦ä¹ ") || combined_text.contains("æ•™è‚²") {
            ContentType::Educational
        } else if combined_text.contains("æ¸¸æˆ") || combined_text.contains("ç”µç«") || combined_text.contains("å®å†µ") {
            ContentType::Gaming
        } else if combined_text.contains("éŸ³ä¹") || combined_text.contains("æ­Œæ›²") || combined_text.contains("MV") {
            ContentType::Music
        } else if combined_text.contains("ç§‘æŠ€") || combined_text.contains("æŠ€æœ¯") || combined_text.contains("ç¼–ç¨‹") {
            ContentType::Technology
        } else if combined_text.contains("æ–°é—»") || combined_text.contains("æ—¶äº‹") || combined_text.contains("æŠ¥é“") {
            ContentType::News
        } else {
            ContentType::Entertainment // Default
        }
    }

    fn analyze_sentiment(&self, title: &str, description: &str) -> Option<f32> {
        // Simple sentiment analysis based on keyword presence
        let positive_words = ["å¥½", "æ£’", "ä¼˜ç§€", "ç²¾å½©", "å®Œç¾", "æ¨è", "å–œæ¬¢", "çˆ±", "ç¾", "å¸…"];
        let negative_words = ["å·®", "çƒ‚", "ç³Ÿç³•", "å¤±æœ›", "è®¨åŒ", "åƒåœ¾", "æ— èŠ", "å", "é”™"];

        let combined_text = format!("{} {}", title, description).to_lowercase();

        let positive_count = positive_words
            .iter()
            .map(|word| combined_text.matches(word).count())
            .sum::<usize>() as f32;

        let negative_count = negative_words
            .iter()
            .map(|word| combined_text.matches(word).count())
            .sum::<usize>() as f32;

        if positive_count + negative_count == 0.0 {
            return None; // Neutral or insufficient data
        }

        let sentiment = (positive_count - negative_count) / (positive_count + negative_count);
        Some(sentiment.clamp(-1.0, 1.0))
    }
}

impl Default for ContentAnalyzer {
    fn default() -> Self {
        Self::new().unwrap()
    }
}